name: ci

on:
  push:
  pull_request:

jobs:
  pip_smoke:
    name: pip smoke (python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install (runtime only)
        run: |
          python -m pip install --upgrade pip
          python -m pip install .

      - name: CLI smoke (doctor + demo)
        run: |
          yolozu doctor --output -
          yolozu demo instance-seg --num-images 2 --image-size 48 --max-instances 2 --run-dir "${RUNNER_TEMP}/yolozu_demo"

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements-dev.txt
          python -m pip install safetensors

      - name: Packaging smoke (pip install + yolozu doctor)
        run: |
          python -m pip install .
          yolozu doctor --output -
          yolozu export --help
          python -c "from yolozu import resources; paths = resources.list_resource_paths(); assert 'schemas/predictions.schema.json' in paths; assert 'protocols/yolo26_eval.json' in paths; print('resources OK:', len(paths))"

      - name: License policy
        run: |
          python tools/check_license_policy.py

      - name: Lint
        run: |
          ruff check .

      - name: Unit tests
        run: |
          python -m unittest

      - name: Migration smoke (migrate + validate)
        run: |
          python - <<'PY'
          import os
          import json
          from pathlib import Path
          from PIL import Image

          out_dir = Path("reports") / "ci_migrate"
          out_dir.mkdir(parents=True, exist_ok=True)

          dataset_root = Path(os.environ["RUNNER_TEMP"]) / "ultra_seg_dataset"
          images = dataset_root / "images" / "val"
          labels = dataset_root / "labels" / "val"
          images.mkdir(parents=True, exist_ok=True)
          labels.mkdir(parents=True, exist_ok=True)
          Image.new("RGB", (32, 32), color=(0, 0, 0)).save(images / "000001.jpg")
          (labels / "000001.txt").write_text("0 0.1 0.1 0.9 0.1 0.9 0.9 0.1 0.9\n", encoding="utf-8")

          data_yaml = Path(os.environ["RUNNER_TEMP"]) / "ultra_data.yaml"
          data_yaml.write_text(
              "\n".join(
                  [
                      f"path: {dataset_root}",
                      "train: images/train",
                      "val: images/val",
                      "task: segment",
                      "",
                  ]
              ),
              encoding="utf-8",
          )
          args_yaml = Path(os.environ["RUNNER_TEMP"]) / "ultra_args.yaml"
          args_yaml.write_text(f"data: {data_yaml}\ntask: segment\n", encoding="utf-8")

          voc_root = Path(os.environ["RUNNER_TEMP"]) / "voc_smoke" / "VOC2012"
          (voc_root / "JPEGImages").mkdir(parents=True, exist_ok=True)
          (voc_root / "SegmentationClass").mkdir(parents=True, exist_ok=True)
          (voc_root / "ImageSets" / "Segmentation").mkdir(parents=True, exist_ok=True)
          (voc_root / "JPEGImages" / "0001.jpg").write_bytes(b"")
          (voc_root / "SegmentationClass" / "0001.png").write_bytes(b"")
          (voc_root / "ImageSets" / "Segmentation" / "val.txt").write_text("0001\n", encoding="utf-8")

          coco_root = Path(os.environ["RUNNER_TEMP"]) / "coco_smoke"
          (coco_root / "images" / "val2017").mkdir(parents=True, exist_ok=True)
          (coco_root / "annotations").mkdir(parents=True, exist_ok=True)
          Image.new("RGB", (64, 32), color=(0, 0, 0)).save(coco_root / "images" / "val2017" / "0001.jpg")
          instances = {
              "images": [{"id": 1, "file_name": "0001.jpg", "width": 64, "height": 32}],
              "annotations": [{"id": 1, "image_id": 1, "category_id": 7, "bbox": [0, 0, 10, 20], "iscrowd": 0}],
              "categories": [{"id": 7, "name": "thing"}],
          }
          (coco_root / "annotations" / "instances_val2017.json").write_text(json.dumps(instances), encoding="utf-8")
          results = [{"image_id": 1, "category_id": 7, "bbox": [0, 0, 10, 20], "score": 0.9}]
          (coco_root / "results.json").write_text(json.dumps(results), encoding="utf-8")
          print("prepared:", dataset_root, data_yaml, args_yaml, voc_root)
          PY

          yolozu migrate dataset \
            --from ultralytics \
            --data "${RUNNER_TEMP}/ultra_data.yaml" \
            --args "${RUNNER_TEMP}/ultra_args.yaml" \
            --output reports/ci_migrate/ultra_wrapper \
            --force

          yolozu validate dataset reports/ci_migrate/ultra_wrapper --split val
          yolozu validate dataset "${RUNNER_TEMP}/ultra_seg_dataset" --split val --label-format segment

          yolozu migrate seg-dataset \
            --from voc \
            --root "${RUNNER_TEMP}/voc_smoke/VOC2012" \
            --split val \
            --output reports/ci_migrate/voc_seg_dataset.json \
            --force

          python - <<'PY'
          import json
          from pathlib import Path
          from yolozu.segmentation_dataset import load_seg_dataset_descriptor

          d = load_seg_dataset_descriptor("reports/ci_migrate/voc_seg_dataset.json")
          assert d.task == "semantic_segmentation"
          assert len(d.samples) == 1

          preds = Path("reports/ci_migrate/seg_preds.json")
          preds.write_text(json.dumps([{"id": "0001", "mask": "pred.png"}]), encoding="utf-8")
          print("ok", preds)
          PY

          yolozu validate seg reports/ci_migrate/seg_preds.json

          yolozu migrate dataset \
            --from coco \
            --coco-root "${RUNNER_TEMP}/coco_smoke" \
            --split val2017 \
            --output reports/ci_migrate/coco_wrapper \
            --force

          yolozu validate dataset reports/ci_migrate/coco_wrapper --split val2017

          yolozu migrate predictions \
            --from coco-results \
            --results "${RUNNER_TEMP}/coco_smoke/results.json" \
            --instances "${RUNNER_TEMP}/coco_smoke/annotations/instances_val2017.json" \
            --output reports/ci_migrate/coco_predictions.json \
            --force

          yolozu validate predictions reports/ci_migrate/coco_predictions.json --strict

          yolozu import dataset \
            --from coco-instances \
            --instances "${RUNNER_TEMP}/coco_smoke/annotations/instances_val2017.json" \
            --images-dir "${RUNNER_TEMP}/coco_smoke/images/val2017" \
            --split val2017 \
            --output reports/ci_migrate/coco_import_wrapper \
            --force

          yolozu validate dataset reports/ci_migrate/coco_import_wrapper --split val2017

      - name: Upload migration artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci_migrate_artifacts
          path: reports/ci_migrate

      - name: Scenario smoke run
        run: |
          if bash tools/fetch_coco128.sh; then
            python tools/run_scenarios.py --adapter dummy --max-images 10
          else
            echo "warning: coco128 fetch failed; running dataset-free scenario suite smoke"
            python tools/run_scenario_suite.py --output reports/scenario_suite_ci.json
          fi

      - name: Training contract smoke (dry-run + ONNX export/parity)
        run: |
          python - <<'PY'
          import os
          from pathlib import Path
          from PIL import Image
          root = Path(os.environ["RUNNER_TEMP"]) / "yolozu_tiny_dataset"
          for split in ("train2017", "val2017"):
              images = root / "images" / split
              labels = root / "labels" / split
              images.mkdir(parents=True, exist_ok=True)
              labels.mkdir(parents=True, exist_ok=True)
              for idx in range(2):
                  name = f"{idx:06d}"
                  img_path = images / f"{name}.jpg"
                  Image.new("RGB", (32, 32), color=(0, 0, 0)).save(img_path)
                  (labels / f"{name}.txt").write_text("0 0.5 0.5 0.2 0.2\n", encoding="utf-8")
          print(root)
          PY

          yolozu train configs/examples/train_contract.yaml \
            --run-id ci_smoke \
            --dry-run \
            --dataset-root "${RUNNER_TEMP}/yolozu_tiny_dataset" \
            --split train2017 \
            --val-split val2017 \
            --device cpu \
            --amp none \
            --ddp-backend gloo \
            --image-size 32 \
            --batch-size 1

          test -f runs/ci_smoke/reports/run_meta.json
          test -f runs/ci_smoke/reports/config_resolved.yaml
          test -f runs/ci_smoke/checkpoints/last.pt
          test -f runs/ci_smoke/checkpoints/best.pt
          test -f runs/ci_smoke/exports/model.onnx
          test -f runs/ci_smoke/reports/onnx_parity.json

          python - <<'PY'
          import json
          from pathlib import Path
          meta = json.loads(Path("runs/ci_smoke/reports/run_meta.json").read_text(encoding="utf-8"))
          assert "host" in meta and isinstance(meta["host"], dict)
          assert "accelerator" in meta and isinstance(meta["accelerator"], dict)
          print("run_meta keys OK")
          PY

      - name: PyInstaller smoke (build + resources list)
        run: |
          python -m pip install pyinstaller
          pyinstaller -y -n yolozu_bin \
            deploy/pyinstaller/yolozu_entrypoint.py \
            --collect-data yolozu.data \
            --collect-data rtdetr_pose
          ./dist/yolozu_bin/yolozu_bin --help
          ./dist/yolozu_bin/yolozu_bin resources list | head -n 5

      - name: PyArmor + PyInstaller smoke (optional)
        if: ${{ vars.PYARMOR_SMOKE == '1' }}
        run: |
          python -m pip install pyarmor
          rm -rf build/pyarmor_obf dist/yolozu_pyarmor yolozu_pyarmor.spec
          pyarmor gen -O build/pyarmor_obf deploy/pyinstaller/yolozu_entrypoint.py
          pyinstaller -y -n yolozu_pyarmor \
            build/pyarmor_obf/yolozu_entrypoint.py \
            --collect-data yolozu.data \
            --collect-data rtdetr_pose
          ./dist/yolozu_pyarmor/yolozu_pyarmor --help

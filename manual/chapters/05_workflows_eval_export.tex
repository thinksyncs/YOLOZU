\chapter{Workflows: Evaluate and Export}

\section{Workflow A: Evaluate existing predictions.json}
If you already have \path{predictions.json} from any inference backend:
\begin{lstlisting}[language=bash]
python3 tools/eval_suite.py \
  --dataset /path/to/yolo-dataset \
  --predictions /path/to/predictions.json
\end{lstlisting}

This is the most common integration path for external inference systems.

\section{Workflow B: Run inference and export predictions}
Depending on your environment:
\begin{itemize}
  \item Torch backend (research): export predictions from a checkpoint.
  \item ONNX Runtime: CPU-friendly export and parity checks.
  \item TensorRT: pinned Linux/NVIDIA pipeline for maximum throughput.
\end{itemize}

Repo wrapper example (conceptual):
\begin{lstlisting}[language=bash]
python3 tools/yolozu.py export \
  --backend onnxrt \
  --dataset /path/to/yolo-dataset \
  --split val \
  --onnx /path/to/model.onnx \
  --out reports/predictions.json
\end{lstlisting}

See:\\
\path{docs/training_inference_export.md} and \path{docs/external_inference.md}.

\section{Workflow C: Folder inference (pip CLI)}
A convenient user-facing path is:
\begin{lstlisting}[language=bash]
yolozu predict-images \
  --backend dummy \
  --input-dir /path/to/images
\end{lstlisting}

This writes a predictions artifact plus optional overlays/HTML to a run directory.

\section{Schema validation as a gate}
Always validate predictions artifacts before evaluation:
\begin{lstlisting}[language=bash]
python3 tools/validate_predictions.py /path/to/predictions.json --strict
\end{lstlisting}

This prevents silent evaluation errors due to malformed outputs.

\section{Workflow D: Migrate datasets/predictions from other toolchains}
YOLOZU includes migration helpers that produce small wrapper artifacts (or converters) so you can reuse common ecosystem datasets.
See \path{docs/migrate.md}.

\subsection{Ultralytics / YOLO (YOLOv8/YOLO11)}
Generate a \path{dataset.json} wrapper from \path{data.yaml}:
\begin{lstlisting}[language=bash]
yolozu migrate dataset \
  --from ultralytics \
  --data /path/to/data.yaml \
  --output data/ultralytics_wrapper
\end{lstlisting}

Validate:
\begin{lstlisting}[language=bash]
yolozu validate dataset data/ultralytics_wrapper
\end{lstlisting}

\subsection{COCO JSON datasets (YOLOX / Detectron2 / MMDetection)}
Convert COCO instances JSON into YOLO label txt files and write a wrapper:
\begin{lstlisting}[language=bash]
yolozu migrate dataset \
  --from coco \
  --coco-root /path/to/coco_like_root \
  --split val2017 \
  --output data/coco_yolo_like \
  --mode manifest
\end{lstlisting}

\subsection{COCO results (inference outputs) \texorpdfstring{$\rightarrow$}{->} predictions.json}
Convert COCO-style detection results into the YOLOZU predictions contract:
\begin{lstlisting}[language=bash]
yolozu migrate predictions \
  --from coco-results \
  --results /path/to/coco_results.json \
  --instances /path/to/instances_val2017.json \
  --output reports/predictions.json \
  --force

yolozu validate predictions reports/predictions.json --strict
\end{lstlisting}

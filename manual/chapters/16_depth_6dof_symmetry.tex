\chapter{Depth + 6DoF Pose + Symmetry Handling}

\ChapterMeta{
Document geometry conventions (units/intrinsics/frames), pose/translation recovery, and symmetry/commonsense constraint utilities.
}{
Improves correctness and robustness of depth/pose pipelines by making assumptions explicit and by providing reusable postprocess gates.
}{
Requires consistent intrinsics after resize/letterbox and consistent units; some metrics/utilities require sidecar metadata (e.g., CAD points) and schema-valid pose fields.
}

\section{Units, intrinsics, and coordinate conventions}
Depth/pose workflows are extremely sensitive to units and to intrinsics consistency.

Key conventions used across docs in this repo:
\begin{itemize}
  \item Intrinsics \cmd{K=(fx,fy,cx,cy)} are in \textbf{pixel units}.
  \item Intrinsics must match the \textbf{image coordinate system used by model outputs} (after resize/letterbox).
  \item Depth \cmd{z} uses the dataset's length unit (YOLOZU does not convert mm\,$\leftrightarrow$\,m).
\end{itemize}

Practical entry points (``real model'' path):
\begin{itemize}
  \item Training scaffold: \cmd{python3 rtdetr_pose/tools/train_minimal.py ...} (writes metrics and optional run artifacts).
  \item Export predictions: \cmd{python3 tools/export_predictions.py --adapter rtdetr_pose ... --wrap}
  \item No-torch path: use the \cmd{precomputed} adapter with a schema-valid \path{predictions.json}.
\end{itemize}

\section{Typical regression heads}
The 6DoF-oriented design documents and utilities assume per-detection regression heads such as:
\begin{itemize}
  \item \cmd{log\_z}: object center depth in log space
  \item \cmd{rot6d}: 6D rotation representation
  \item \cmd{offsets}: center correction \cmd{(\u0394u,\u0394v)}
  \item \cmd{k\_delta}: small intrinsics correction (global / per-frame)
\end{itemize}

See the design spec for clear definitions of frames and outputs:\\
\path{docs/specs/rt_detr_6dof_geom_mim_spec_en_v0_4.md}.

\section{Translation recovery (postprocess)}
A common pattern is to recover translation from depth + intrinsics:

Let bbox center be $(u,v)$ and corrected center $(u',v')$ be:
$$
  u' = u + \Delta u, \qquad v' = v + \Delta v.
$$

Let corrected intrinsics be $K'=(f_x', f_y', c_x', c_y')$.
Then with $Z=z$:
$$
  X = \frac{u' - c_x'}{f_x'} Z, \qquad
  Y = \frac{v' - c_y'}{f_y'} Z.
$$

The point of this design is to avoid unstable direct regression of $(X,Y)$.

\section{Commonsense constraints (Stage 4, implemented utilities)}
This repository contains a small, test-covered set of \textbf{commonsense constraints} for depth/pose postprocess.
They are designed as \textbf{utilities} (not a full end-to-end model training system) and can be used both as
train-time regularizers and as inference-time gates/penalties.

Implementation / configuration:
\begin{itemize}
  \item Core logic: \path{yolozu/constraints.py}
  \item Runtime config: \path{configs/runtime/constraints.yaml}
\end{itemize}

Key pieces (matching the Stage 4 roadmap vocabulary):
\begin{itemize}
  \item Depth prior: \cmd{depth\_prior(bbox\_wh, size\_wh, (fx,fy))} and penalty \cmd{depth\_prior\_penalty(z\_pred, z\_prior)}.
  \item Table plane: signed distance via \cmd{plane\_signed\_distance(...)} and below-plane rejection via \cmd{is\_above\_plane(...)}.
  \item Upright prior: roll/pitch extraction and violation via \cmd{upright\_violation\_deg(R, bounds)}.
\end{itemize}

Wiring example:
\begin{itemize}
  \item Candidate evaluation calls constraints from \path{yolozu/pipeline.py} (\cmd{evaluate\_candidate}).
\end{itemize}

Ablations:
\begin{itemize}
  \item Toggle each constraint: \path{tools/ablate_constraints.py}
\end{itemize}

Tests (unit + integration toggles):
\begin{itemize}
  \item \path{tests/test\_gates\_constraints.py}
  \item \path{tests/test\_inference\_constraints.py}
\end{itemize}

\section{Handheld camera robustness (Stage 5, implemented utilities)}
Stage 5 focuses on robustness to camera perturbations by consistently using corrected intrinsics $K'$ and
center offsets $(u+\Delta u, v+\Delta v)$.

Implementation entry points:
\begin{itemize}
  \item Intrinsics correction: \path{yolozu/geometry.py} (\cmd{corrected\_intrinsics})
  \item Translation recovery using offsets: \path{yolozu/geometry.py} (\cmd{recover\_translation})
  \item Jitter profile utilities: \path{yolozu/jitter.py}
\end{itemize}

Jitter utilities provide:
\begin{itemize}
  \item Intrinsics drift sampling (e.g. $\delta f,\delta c$): \cmd{sample\_intrinsics\_jitter(...)}
  \item Extrinsics jitter sampling: \cmd{sample\_extrinsics\_jitter(...)}
  \item A baseline profile with jitter disabled: \cmd{jitter\_off()}
\end{itemize}

Note: the jitter profile includes a \cmd{rolling\_shutter} field (\cmd{enabled}, \cmd{line\_delay}), but the current
repository code treats it as a configuration stub; there is no physics-accurate rolling shutter model wired into
the core geometry utilities.

Tests (integration-level expectations for jitter on/off profiles):
\begin{itemize}
  \item \path{tests/test\_geometry\_pipeline.py}
  \item \path{rtdetr\_pose/tests/test\_train\_minimal\_sim\_jitter.py}
  \item \path{rtdetr\_pose/tests/test\_train\_minimal\_extrinsics\_jitter.py}
\end{itemize}

\section{Scenario suite (Stage 6, scaffolded validation harness)}
The validation harness includes a lightweight \textbf{scenario suite} that emits a stable JSON report for CI and
tooling integration.

Implementation / schema:
\begin{itemize}
  \item Scenario suite generator: \path{yolozu/scenario\_suite.py} (\cmd{build\_report})
  \item CLI wrapper: \path{tools/run\_scenario\_suite.py}
  \item Schema-style stability test: \path{tests/test\_scenario\_suite.py}
\end{itemize}

Run it manually:
\begin{lstlisting}[language=bash]
python tools/run_scenario_suite.py --output reports/scenario_suite.json
\end{lstlisting}

Important: the current scenario suite produces \textbf{scaffolded/deterministic metrics} (it is a harness and
contract surface), not a substitute for real model evaluation.

\section{Per-detection refinement: Hessian solver}
\yolozu{} includes a Gauss--Newton / Levenberg--Marquardt style refinement utility to iteratively refine
regression head outputs per detection.

Key idea: refine per-detection parameters (depth/rotation/offsets) with bounded iterations; treat it as a research postprocess (not a default real-time feature).

\subsection{CLI}
Refine depth (example):
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --refine-depth
\end{lstlisting}

Refine depth + rotation (bounded iterations):
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --refine-depth \
  --refine-rotation \
  --max-iterations 10
\end{lstlisting}

\subsection{How it differs from calibration}
\begin{itemize}
  \item Hessian refinement is \textbf{per detection} (local improvements).
  \item L-BFGS calibration is typically \textbf{dataset-wide} (global scale/intrinsics style parameters).
\end{itemize}

Use refinement when you have supervision/constraints and you want to improve individual predictions.
Avoid it for real-time production unless the added latency is justified.

\section{Symmetry: why it matters}
For symmetric objects, a single canonical rotation label may not be unique.
Na\"ively training with a standard rotation loss can be ill-posed and can also break template-based verification.

\section{Symmetry metadata (runtime configuration)}
The preferred approach is deterministic, class-level symmetry metadata.
The runtime config exists at:
\begin{itemize}
  \item \path{configs/runtime/symmetry.json}
\end{itemize}

The expected shape (from the spec) looks like:
\begin{lstlisting}[language=json]
{
  "class_id_or_name": {
    "type": "none | Cn | Dn | Cinf | mirror",
    "n": 4,
    "axis": [0, 0, 1],
    "notes": "optional"
  }
}
\end{lstlisting}

Note: in a fresh checkout, \path{configs/runtime/symmetry.json} may be empty (\cmd{\{\}}). Populate it for your class set.

\section{Symmetry-aware loss / metrics (concept)}
A symmetry-aware rotation distance is commonly expressed as:
$$
  L_{rot}^{sym} = \min_{S \in G} d(R_{pred}, R_{gt} \cdot S)
$$
where $G$ is the symmetry group for the object.

For context and intended gates (including real-time constraints), see:
\begin{itemize}
  \item \path{docs/specs/rt_detr_6dof_geom_mim_spec_en_v0_4.md}
  \item \path{docs/roadmaps/symmetry_commonsense_realtime.md} (historical notes)
\end{itemize}

\section{Available evaluation metrics (current implementation)}
The pose/depth evaluator (\path{yolozu/pose_eval.py}) reports these keys:
\begin{itemize}
  \item Depth: \cmd{depth\_abs\_mean}, \cmd{depth\_abs\_median}
  \item Pose core: \cmd{rot\_deg\_mean}, \cmd{trans\_l2\_mean}, \cmd{pose\_success}
  \item CAD-point pose: \cmd{add\_mean}, \cmd{add\_median}, \cmd{adds\_mean}, \cmd{adds\_median}
\end{itemize}

Definitions:
\begin{itemize}
  \item \textbf{ADD}: mean point distance under fixed point correspondence between $(R_{pred}, t_{pred})$ and $(R_{gt}, t_{gt})$.
  \item \textbf{ADDS}: mean distance from each transformed predicted point to its nearest transformed GT point.
\end{itemize}

Input requirements:
\begin{itemize}
  \item Depth metrics require valid GT translation/depth and predicted depth or translation.
  \item ADD/ADDS require CAD points in sidecar metadata (\cmd{cad\_points} / \cmd{cad\_path} / \cmd{cad\_points\_path}) plus valid GT+pred pose.
\end{itemize}

\section{Practical advice}
\begin{itemize}
  \item First, make unit/intrinsics consistency boring and deterministic.
  \item Next, ensure evaluation metrics treat symmetry correctly for relevant classes.
  \item Keep symmetry/commonsense logic out of the TensorRT graph when possible; run it in postprocess.
\end{itemize}

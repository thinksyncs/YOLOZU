\chapter{Depth + 6DoF Pose + Symmetry Handling}

\ChapterMeta{
This chapter documents geometry conventions (units, intrinsics, and coordinate frames), pose and translation recovery, and symmetry and commonsense constraint utilities.
}{
It improves correctness and robustness of depth and pose pipelines by making assumptions explicit and by providing reusable postprocess gates.
}{
It requires consistent intrinsics after resize and letterbox, and consistent units; some metrics and utilities require sidecar metadata (for example CAD points) and schema-valid pose fields.
}

\section{Units, intrinsics, and coordinate conventions}
Depth/pose workflows are extremely sensitive to units and to intrinsics consistency.

Key conventions used across docs in this repo:
\begin{itemize}
  \item Intrinsics \cmd{K=(fx,fy,cx,cy)} are in \textbf{pixel units}.
  \item Intrinsics must match the \textbf{image coordinate system used by model outputs} (after resize/letterbox).
  \item Depth \cmd{z} uses the dataset's length unit (YOLOZU does not convert mm\,$\leftrightarrow$\,m).
\end{itemize}

Depth integration modes in the scaffold trainer:
\begin{itemize}
  \item \cmd{none}: depth disabled (compatibility default).
  \item \cmd{sidecar}: depth is read from sidecar metadata (\cmd{depth_path}/\cmd{depth}) and tracked via \cmd{depth_valid}.
  \item \cmd{fuse_mid}: depth is fused after projector (outside backbone \([P3,P4,P5]\) swap boundary).
\end{itemize}

Metric safety rule:
\begin{itemize}
  \item Use \cmd{--depth-unit metric} when absolute depth costs are intended.
  \item For \cmd{unspecified}/\cmd{relative}, absolute depth matcher terms are disabled for safety.
\end{itemize}

Example:
\begin{lstlisting}[language=bash]
python3 rtdetr_pose/tools/train_minimal.py \
  --dataset-root data/coco128 \
  --config rtdetr_pose/configs/base.json \
  --use-matcher \
  --depth-mode sidecar \
  --depth-unit metric \
  --depth-scale 1.0
\end{lstlisting}

Practical entry points (``real model'' path):
\begin{itemize}
  \item Training scaffold: \cmd{python3 -m rtdetr_pose.train_minimal ...} (writes metrics and optional run artifacts).
  \item Export predictions: \cmd{python3 tools/export_predictions.py --adapter rtdetr_pose ... --wrap}
  \item No-torch path: use the \cmd{precomputed} adapter with a schema-valid \path{predictions.json}.
\end{itemize}

\section{Typical regression heads}
The 6DoF-oriented design documents and utilities assume per-detection regression heads such as:
\begin{itemize}
  \item \cmd{log_z}: object center depth in log space
  \item \cmd{rot6d}: 6D rotation representation \cite{zhou2019rot6d}
  \item \cmd{offsets}: center correction $(\Delta u,\Delta v)$
  \item \cmd{k_delta}: small intrinsics correction (global / per-frame)
\end{itemize}

See the design spec for clear definitions of frames and outputs:\\
\path{docs/specs/rt_detr_6dof_geom_mim_spec_en_v0_4.md}.

\section{Translation recovery (postprocess)}
A common pattern is to recover translation from depth + intrinsics:
For monocular depth estimation background (if you learn depth from RGB), see \cite{eigen2014depth,ranftl2021dpt}.

Let bbox center be $(u,v)$ and corrected center $(u',v')$ be:
$$
  u' = u + \Delta u, \qquad v' = v + \Delta v.
$$

Let corrected intrinsics be $K'=(f_x', f_y', c_x', c_y')$.
Then with $Z=z$:
$$
  X = \frac{u' - c_x'}{f_x'} Z, \qquad
  Y = \frac{v' - c_y'}{f_y'} Z.
$$

The point of this design is to avoid unstable direct regression of $(X,Y)$.

\section{Commonsense constraints (Stage 4, implemented utilities)}
This repository contains a small, test-covered set of \textbf{commonsense constraints} for depth/pose postprocess.
They are designed as \textbf{utilities} (not a full end-to-end model training system) and can be used both as
train-time regularizers and as inference-time gates/penalties.

Implementation / configuration:
\begin{itemize}
  \item Core logic: \path{yolozu/constraints.py}
  \item Runtime config: \path{configs/runtime/constraints.yaml}
\end{itemize}

Key pieces (matching the Stage 4 roadmap vocabulary):
\begin{itemize}
  \item Depth prior: \\
    \cmd{depth_prior(bbox_wh, size_wh, (fx,fy))} \\
    and penalty \cmd{depth_prior_penalty(z_pred, z_prior)}.
  \item Table plane: signed distance via \cmd{plane_signed_distance(...)}
    and below-plane rejection via \cmd{is_above_plane(...)}.
  \item Upright prior: roll/pitch extraction and violation via \\
    \cmd{upright_violation_deg(R, bounds)}.
\end{itemize}

Wiring example:
\begin{itemize}
  \item Candidate evaluation calls constraints from \path{yolozu/pipeline.py} (\cmd{evaluate_candidate}).
\end{itemize}

Ablations:
\begin{itemize}
  \item Toggle each constraint: \path{tools/ablate_constraints.py}
\end{itemize}

Tests (unit + integration toggles):
\begin{itemize}
  \item \path{tests/test_gates_constraints.py}
  \item \path{tests/test_inference_constraints.py}
\end{itemize}

\section{Handheld camera robustness (Stage 5, implemented utilities)}
Stage 5 focuses on robustness to camera perturbations by consistently using corrected intrinsics $K'$ and
center offsets $(u+\Delta u, v+\Delta v)$.

Implementation entry points:
\begin{itemize}
  \item Intrinsics correction: \path{yolozu/geometry.py} (\cmd{corrected_intrinsics})
  \item Translation recovery using offsets: \path{yolozu/geometry.py} (\cmd{recover_translation})
  \item Jitter profile utilities: \path{yolozu/jitter.py}
\end{itemize}

Jitter utilities provide:
\begin{itemize}
  \item Intrinsics drift sampling (e.g. $\delta f,\delta c$): \cmd{sample\_intrinsics_jitter(...)}
  \item Extrinsics jitter sampling: \cmd{sample\_extrinsics_jitter(...)}
  \item A baseline profile with jitter disabled: \cmd{jitter_off()}
\end{itemize}

Note: the jitter profile includes a \cmd{rolling_shutter} field (\cmd{enabled}, \cmd{line_delay}), but the current
repository code treats it as a configuration stub; there is no physics-accurate rolling shutter model wired into
the core geometry utilities.

Tests (integration-level expectations for jitter on/off profiles):
\begin{itemize}
  \item \path{tests/test_geometry_pipeline.py}
  \item \path{rtdetr_pose/tests/test_train_minimal_sim_jitter.py}
  \item \path{rtdetr_pose/tests/test_train_minimal_extrinsics_jitter.py}
\end{itemize}

\section{Scenario suite (Stage 6, scaffolded validation harness)}
The validation harness includes a lightweight \textbf{scenario suite} that emits a stable JSON report for CI and
tooling integration.

Implementation / schema:
\begin{itemize}
  \item Scenario suite generator: \path{yolozu/scenario_suite.py} (\cmd{build_report})
  \item CLI wrapper: \path{tools/run_scenario_suite.py}
  \item Schema-style stability test: \path{tests/test_scenario_suite.py}
\end{itemize}

Run it manually:
\begin{lstlisting}[language=bash]
python tools/run_scenario_suite.py --output reports/scenario_suite.json
\end{lstlisting}

Important: the current scenario suite produces \textbf{scaffolded/deterministic metrics} (it is a harness and
contract surface), not a substitute for real model evaluation.

\section{Per-detection refinement: Hessian solver}
\yolozu{} includes a Gauss--Newton / Levenberg--Marquardt style refinement utility to iteratively refine
regression head outputs per detection \cite{levenberg1944,marquardt1963lm}.

Key idea: refine per-detection parameters (depth/rotation/offsets) with bounded iterations; treat it as a research postprocess (not a default real-time feature).

\subsection{CLI}
Refine depth (example):
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --refine-depth
\end{lstlisting}

Refine depth + rotation (bounded iterations):
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --refine-depth \
  --refine-rotation \
  --max-iterations 10
\end{lstlisting}

\subsection{How it differs from calibration}
\begin{itemize}
  \item Hessian refinement is \textbf{per detection} (local improvements).
  \item L-BFGS calibration is typically \textbf{dataset-wide} (global scale/intrinsics style parameters).
\end{itemize}

Use refinement when you have supervision/constraints and you want to improve individual predictions.
Avoid it for real-time production unless the added latency is justified.

\section{Symmetry: why it matters}
For symmetric objects, a single canonical rotation label may not be unique.
Na\"ively training with a standard rotation loss can be ill-posed and can also break template-based verification.

\section{Symmetry metadata (runtime configuration)}
The preferred approach is deterministic, class-level symmetry metadata.
The runtime config exists at:
\begin{itemize}
  \item \path{configs/runtime/symmetry.json}
\end{itemize}

The expected shape (from the spec) looks like:
\begin{lstlisting}[language=json]
{
  "class_id_or_name": {
    "type": "none | Cn | Dn | Cinf | mirror",
    "n": 4,
    "axis": [0, 0, 1],
    "notes": "optional"
  }
}
\end{lstlisting}

Note: in a fresh checkout, \path{configs/runtime/symmetry.json} may be empty (\cmd{\{\}}). Populate it for your class set.

\section{Symmetry-aware loss / metrics (concept)}
A symmetry-aware rotation distance is commonly expressed as:
$$
  L_{rot}^{sym} = \min_{S \in G} d(R_{pred}, R_{gt} \cdot S)
$$
where $G$ is the symmetry group for the object.

For context and intended gates (including real-time constraints), see:
\begin{itemize}
  \item \path{docs/specs/rt_detr_6dof_geom_mim_spec_en_v0_4.md}
  \item \path{docs/roadmaps/symmetry_commonsense_realtime.md} (historical notes)
\end{itemize}

\section{Available evaluation metrics (current implementation)}
The pose/depth evaluator (\path{yolozu/pose_eval.py}) reports these keys:
\begin{itemize}
  \item Depth: \cmd{depth\_abs_mean}, \cmd{depth\_abs_median}
  \item Pose core: \cmd{rot\_deg_mean}, \cmd{trans\_l2_mean}, \cmd{pose_success}
  \item CAD-point pose: \cmd{add_mean}, \cmd{add_median}, \cmd{adds_mean}, \cmd{adds_median}
\end{itemize}

Definitions:
\begin{itemize}
  \item \textbf{ADD}: mean point distance under fixed point correspondence between $(R_{pred}, t_{pred})$ and $(R_{gt}, t_{gt})$.
  \item \textbf{ADDS}: mean distance from each transformed predicted point to its nearest transformed GT point.
\end{itemize}

These pose metrics and the symmetry caveats around them are discussed in standard 6D pose evaluation literature \cite{hodan2016poseeval,hodan2020bop}.
For an example of a modern end-to-end 6D pose system (useful as conceptual background), see \cite{labbe2020cosypose}.

Input requirements:
\begin{itemize}
  \item Depth metrics require valid GT translation/depth and predicted depth or translation.
  \item ADD/ADDS require CAD points in sidecar metadata \\
    (\cmd{cad_points} / \cmd{cad_path} / \cmd{cad_points_path}) \\
    plus valid GT+pred pose.
\end{itemize}

\section{Practical advice}
\begin{itemize}
  \item First, make unit/intrinsics consistency boring and deterministic.
  \item Next, ensure evaluation metrics treat symmetry correctly for relevant classes.
  \item Keep symmetry/commonsense logic out of the TensorRT graph when possible; run it in postprocess.
\end{itemize}

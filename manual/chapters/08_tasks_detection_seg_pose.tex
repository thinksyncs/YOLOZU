\chapter{Tasks: Detection, Segmentation, Keypoints}

\ChapterMeta{
This chapter delineates the supported task families and rigorously defines their expected prediction schemas.
}{
Adhering to these specifications prevents schema mismatches and guarantees the application of the correct evaluator for each task, thereby enhancing metric accuracy and streamlining the debugging process.
}{
It assumes the presence of task-specific data fields (e.g., PNG masks for instance segmentation, and keypoint arrays for pose estimation); it is highly recommended to validate artifacts early using the provided utility tools.
}

\section{Bounding-box detection}
Bounding-box detection serves as the foundational task, generating per-image detections characterized by class IDs, bounding box coordinates, and confidence scores. Evaluation is predominantly conducted using COCO-style mean Average Precision (mAP) or other protocol-pinned metrics.

\section{Instance segmentation (PNG masks)}
\yolozu{} evaluates instance segmentation utilizing \textbf{per-instance binary PNG masks}. This approach deliberately circumvents the complexities associated with Run-Length Encoding (RLE) or polygon-based tooling.

The minimal required prediction schema is structured as follows:
\begin{lstlisting}[language=json]
[
  {
    "image": "000001.png",
    "instances": [
      {"class_id": 0, "score": 0.9, "mask": "masks/000001_inst0.png"}
    ]
  }
]
\end{lstlisting}

To validate the schema:
\begin{lstlisting}[language=bash]
python3 tools/validate_instance_segmentation_predictions.py   reports/instance_seg_predictions.json
\end{lstlisting}

To execute evaluation and generate visual overlays and HTML reports:
\begin{lstlisting}[language=bash]
python3 tools/eval_instance_segmentation.py   --dataset /path/to/dataset   --split val   --predictions /path/to/predictions.json   --pred-root /path/to/pred-root   --classes /path/to/classes.txt   --html reports/instance_seg_eval.html   --overlays-dir reports/instance_seg_overlays   --max-overlays 10
\end{lstlisting}

\section{Semantic segmentation}
The semantic segmentation suite provides robust dataset preparation utilities and mean Intersection over Union (mIoU) evaluation capabilities. While semantic segmentation evaluation yields mIoU (alongside per-class IoU), instance segmentation evaluation outputs COCO-style mask mAP. Ensure you utilize \path{tools/eval_segmentation.py} for semantic segmentation tasks and \path{tools/eval_instance_segmentation.py} for instance segmentation.

\section{Keypoints / pose estimation}
\yolozu{} fully supports YOLO pose-style keypoints within both labels and predictions, complemented by dedicated evaluation utilities. Depending on your specific workflow requirements, you may employ Percentage of Correct Keypoints (PCK) evaluation, COCO Object Keypoint Similarity (OKS) mAP, or both.

Dataset preparation is streamlined into a single command:
\begin{lstlisting}[language=bash]
python3 tools/yolozu.py prepare-keypoints-dataset   --source /path/to/export   --format auto   --out /path/to/keypoints_dataset
\end{lstlisting}

Supported direct input formats include: \cmd{auto}, \cmd{yolo_pose}, \cmd{coco}, and \cmd{cvat_xml}. When processing CVAT XML, you may provide either a specific XML file or a directory containing an \path{annotations.xml} file. If the image root inference is ambiguous, explicitly define it using the \cmd{--cvat-images-dir} parameter.

A minimal smoke test for CVAT XML processing:
\begin{lstlisting}[language=bash]
python3 -m pytest -q tests/test_prepare_keypoints_dataset_cvat_xml.py
\end{lstlisting}

Keypoint evaluation entry points are accessible via scripts located in the \path{tools/} directory (e.g., keypoint evaluation helpers). Please consult the repository documentation for the authoritative schema definitions and comprehensive usage instructions.

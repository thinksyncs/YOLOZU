\chapter{Hessian-based Refinement (Practical)}

\ChapterMeta{
This chapter introduces per-detection numerical refinement using a Hessian-based Gauss--Newton style solver after inference.
}{
It can reduce errors on difficult samples in offline analysis and controlled studies by applying iterative local corrections.
}{
It is best suited for offline and batch workflows where extra compute is acceptable; it requires predictions and dataset context and uses convergence and damping parameters.
}

\section{Scope and relation to TTT}
This chapter focuses on per-detection numerical refinement after inference.
TTT/Tent/MIM adaptation policy is covered in Chapter~15 to avoid duplicated guidance.

\section{What the Hessian solver does}
The Hessian solver refines prediction values per detection using Gauss--Newton style updates with Levenberg--Marquardt damping.

Current standard CLI path is engine-external post-processing on predictions JSON, with offsets refinement as the initial target.

At a high level, each iteration computes residuals and Jacobian, solves a damped normal equation,
updates parameters, and stops when convergence criteria are met.

\section{When to use it}
Recommended situations:
\begin{itemize}
  \item offline validation/analysis where GT supervision or geometric constraints are available,
  \item targeted error reduction on difficult samples,
  \item post-inference refinement studies after global calibration.
\end{itemize}

Avoid by default in strict real-time production because it adds latency.

\section{CLI quickstart}
Enable refinement (opt-in):
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --enable \
  --refine-offsets \
  --wrap
\end{lstlisting}

Disable (pass-through) explicitly:
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --output reports/predictions_refined.json \
  --disable \
  --wrap
\end{lstlisting}

Enable with custom solver controls:
\begin{lstlisting}[language=bash]
python tools/refine_predictions_hessian.py \
  --predictions reports/predictions.json \
  --dataset data/coco128 \
  --output reports/predictions_refined.json \
  --enable \
  --refine-offsets \
  --steps 10 \
  --damping 1e-2
\end{lstlisting}

\section{Core knobs}
Commonly tuned parameters (matching \path{docs/hessian_solver.md}):
\begin{itemize}
  \item gate/control: \cmd{--enable}/\cmd{--disable}, \cmd{steps}, \cmd{damping}, \cmd{fd_eps}
  \item target toggles: \cmd{refine_offsets} (offsets-first rollout)
  \item residual weights: \cmd{w_depth}, \cmd{w_mask}, \cmd{w_reg}
  \item config file: \cmd{--config <yaml|json>} (CLI values override config)
\end{itemize}

\section{Position in the workflow}
A practical ordering is:
\begin{enumerate}
  \item train model,
  \item optionally run dataset-wide calibration (global scale/intrinsics),
  \item apply Hessian refinement only where per-detection correction is needed.
\end{enumerate}

This chapter lists the common knobs; for the full parameter surface, rely on the tool's \cmd{--help} output (kept in sync with code).

TensorRT note: TRT conversion targets inference graph execution; Hessian refinement is a separate engine-external post-processing step.

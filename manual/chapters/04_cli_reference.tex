\chapter{CLI Reference (Practical)}

\section{Philosophy}
The CLI surface is intentionally split:
\begin{itemize}
  \item \cmd{yolozu}: end-user safe CLI (installed via pip).
  \item \cmd{python3 tools/yolozu.py}: repository wrapper for research/eval pipelines.
\end{itemize}

This chapter documents the \textit{high-traffic commands} and how to discover the rest.

\section{Discoverability}
Always start with:\\
\cmd{yolozu --help} and \cmd{yolozu <command> --help}.\\
For repo workflows: \cmd{python3 tools/yolozu.py --help}.

\section{Common commands}
\begin{longtable}{@{}p{0.24\textwidth}p{0.70\textwidth}@{}}
\toprule
\textbf{Command} & \textbf{Purpose} \\
\midrule
\cmd{yolozu doctor} & Environment diagnostics (deps/GPU/backend availability). \\
\cmd{yolozu train} & YAML/JSON config-driven RT-DETR training (supports run contract and resume). \\
\cmd{yolozu test} & YAML/JSON scenario runner (dummy/precomputed/rtdetr\_pose adapters). \\
\cmd{yolozu predict-images} & Folder inference \(\to\) predictions + overlays + HTML. \\
\cmd{yolozu eval-coco} & COCO mAP evaluation from predictions.json (when COCO tooling installed). \\
\cmd{yolozu parity} & Compare two predictions artifacts (backend drift checks). \\
\cmd{yolozu calibrate} & Score calibration / long-tail post-hoc adjustments. \\
\cmd{python3 tools/eval_suite.py} & Suite evaluation; protocol-pinned reporting and comparisons. \\
\cmd{python3 tools/hpo_sweep.py} & Execute parameter sweeps and aggregate metrics (CSV/MD/JSONL). \\
\cmd{python3 tools/benchmark_latency.py} & Latency/FPS harness with JSONL history for regressions. \\
\cmd{python3 tools/validate_tool_manifest.py} & Validate the machine-readable registry (tools/manifest.json). \\
\bottomrule
\end{longtable}

\section{YAML config-driven usage (train/test/resume)}
\yolozu{} supports passing a YAML/JSON file as the first positional argument.
Internally, \cmd{yolozu train} forwards \cmd{--config <file>} to
\path{rtdetr\_pose.train\_minimal}, and \cmd{yolozu test} converts YAML keys to
\path{yolozu.scenarios\_cli} arguments.

\begin{longtable}{@{}p{0.18\textwidth}p{0.30\textwidth}p{0.46\textwidth}@{}}
\toprule
\textbf{Case} & \textbf{YAML file} & \textbf{Command pattern} \\
\midrule
Train (default) & \path{configs/examples/train\_setting.yaml} & \cmd{yolozu train <train\_setting.yaml>} \\
Train (contract) & \path{configs/examples/train\_contract.yaml} & \cmd{yolozu train <train\_contract.yaml> --run-id <id>} \\
Resume & same as train contract & \cmd{yolozu train <train\_contract.yaml> --run-id <id> --resume} \\
Test (scenario) & \path{configs/examples/test\_setting.yaml} & \cmd{yolozu test <test\_setting.yaml> [test\_args...]} \\
\bottomrule
\end{longtable}

Concrete examples:
\begin{lstlisting}[language=bash]
yolozu train configs/examples/train_setting.yaml
yolozu train configs/examples/train_contract.yaml --run-id exp01
yolozu train configs/examples/train_contract.yaml --run-id exp01 --resume
yolozu test configs/examples/test_setting.yaml --adapter precomputed --predictions reports/predictions.json
\end{lstlisting}

\subsection{Test YAML and override rule}
The default test YAML is intentionally minimal (adapter/dataset/split/max\_images), and runtime-specific
options are typically passed as CLI overrides:
\begin{lstlisting}[language=bash]
yolozu test configs/examples/test_setting.yaml \
  --adapter rtdetr_pose \
  --config rtdetr_pose/configs/base.json \
  --checkpoint /path/to/checkpoint.pt \
  --dataset data/coco128 \
  --max-images 50
\end{lstlisting}

\noindent This mirrors the documented real-model flow in \path{docs/real\_model\_interface.md}.

\section{Repository power tools}
Many task-specific scripts live under \path{tools/}. Examples include:
\begin{itemize}
  \item \path{tools/validate_predictions.py}
  \item \path{tools/eval_instance_segmentation.py}
  \item \path{tools/eval_segmentation.py}
  \item \path{tools/export_predictions.py} (adapter-based export)
\end{itemize}

For a comprehensive list, see \path{docs/tools_index.md} and \path{tools/manifest.json}.

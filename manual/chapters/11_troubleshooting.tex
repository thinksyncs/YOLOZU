\chapter{Troubleshooting}

\ChapterMeta{
This chapter provides an accelerated debugging playbook: it emphasizes validating artifacts first, followed by investigating common integration failure modes.
}{
Adhering to this playbook drastically shortens iteration times by identifying schema violations, pathing errors, and class-mapping discrepancies before you attempt to interpret potentially flawed metrics.
}{
It is most effective when validators are executed on the exact artifacts slated for evaluation. Pay meticulous attention to the \cmd{--pred-root} parameter and ensure consistent class ordering between the exporter and the evaluator.
}

\section{Validate early and often}
If evaluation results appear anomalous, your immediate first step must be artifact validation.

To validate the standard predictions schema:
\begin{lstlisting}[language=bash]
python3 tools/validate_predictions.py /path/to/predictions.json --strict
\end{lstlisting}

To validate instance segmentation predictions:
\begin{lstlisting}[language=bash]
python3 tools/validate_instance_segmentation_predictions.py /path/to/preds.json
\end{lstlisting}

\section{Common failure modes}
\begin{itemize}
  \item \textbf{Pathing issues}: Relative paths embedded within the JSON artifact fail to resolve correctly against the specified \cmd{--pred-root}.
  \item \textbf{Class mapping mismatches}: The ordering defined in \path{classes.txt} diverges from the internal mapping utilized by the model or exporter.
  \item \textbf{Backend discrepancies}: Pre-processing or post-processing logic varies subtly across different inference backends.
  \item \textbf{TensorRT environment constraints}: TensorRT execution is strictly pinned to Linux/NVIDIA environments; you must utilize the documented container workflow to ensure compatibility.
\end{itemize}

\section{Further reading and resources}
\begin{itemize}
  \item Tools index: \path{docs/tools_index.md}
  \item External inference documentation: \path{docs/external_inference.md}
  \item Predictions schema specification: \path{docs/predictions_schema.md}
  \item Training and export overview: \path{docs/training_inference_export.md}
\end{itemize}
